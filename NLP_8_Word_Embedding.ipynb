{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NLP 8 : Word Embedding",
      "provenance": [],
      "authorship_tag": "ABX9TyMYlzElXsPoP2fKJ8/KKant",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ianuvrat/NLP/blob/main/NLP_8_Word_Embedding.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XtJYSOwOD4d4"
      },
      "source": [
        "Word Embedding Techniques using Embedding Layer in Keras"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7Lmxf5QsDpLE"
      },
      "source": [
        "# Libraries USed Tensorflow> 2.0  and keras"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iG0KTd9ADzcz"
      },
      "source": [
        "##tensorflow >2.0"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eJjLQ8mjECsx"
      },
      "source": [
        "##tensorflow >2.0\n",
        "from tensorflow.keras.preprocessing.text import one_hot"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TXHUSn6_EEA2"
      },
      "source": [
        "\n",
        "### sentences                                                #initializing sentences\n",
        "sent=[  'the glass of milk and sugar',\n",
        "     'the glass of juice',\n",
        "     'the cup of tea',\n",
        "    'I am a good boy',\n",
        "     'I am a good developer',\n",
        "     'understand the meaning of words',\n",
        "     'your videos are good',]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EdlrQ-OzEOBn",
        "outputId": "6fa92790-44b9-4cb5-9b80-12e9809a5d91",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "sent"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['the glass of milk and sugar',\n",
              " 'the glass of juice',\n",
              " 'the cup of tea',\n",
              " 'I am a good boy',\n",
              " 'I am a good developer',\n",
              " 'understand the meaning of words',\n",
              " 'your videos are good']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z4RkUwlgES5b"
      },
      "source": [
        "### Vocabulary size\n",
        "voc_size=10000"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u34QkjU8FOyG"
      },
      "source": [
        "One Hot Representation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0Dq6BA8rEWa5",
        "outputId": "bac003da-9188-49a9-c29a-dd4f5a4c5f90",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "onehot_repr=[one_hot(words,voc_size)for words in sent]       #getting index from dictionary by passing 'word' in 'vocab size'\n",
        "print(onehot_repr)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[8817, 5545, 6569, 6818, 7452, 1393], [8817, 5545, 6569, 383], [8817, 6606, 6569, 1889], [3730, 537, 8548, 8432, 9057], [3730, 537, 8548, 8432, 326], [5409, 8817, 990, 6569, 1343], [9441, 2316, 3673, 8432]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZHfo-J2hG0Sr"
      },
      "source": [
        "Word Embedding Represntation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ao44j-zRFT-_"
      },
      "source": [
        "from tensorflow.keras.layers import Embedding                              #Embedding layer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences          #Padding 0's beforethe numbers\n",
        "from tensorflow.keras.models import Sequential                             #Sequential layer\n",
        "import numpy as np"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KYh8l1VQG5u4",
        "outputId": "22c737e7-e438-4c12-faf8-bdcb6dc1f8d0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "sent_length=8                                                              #Length of sentence\n",
        "embedded_docs=pad_sequences(onehot_repr,padding='pre',maxlen=sent_length)  #Introducing 0's beforehand\n",
        "print(embedded_docs)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[   0    0 8817 5545 6569 6818 7452 1393]\n",
            " [   0    0    0    0 8817 5545 6569  383]\n",
            " [   0    0    0    0 8817 6606 6569 1889]\n",
            " [   0    0    0 3730  537 8548 8432 9057]\n",
            " [   0    0    0 3730  537 8548 8432  326]\n",
            " [   0    0    0 5409 8817  990 6569 1343]\n",
            " [   0    0    0    0 9441 2316 3673 8432]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1gQ351HzJGZX"
      },
      "source": [
        "dim=10                                                                 #intitalizing dimensions (or features size)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yPiM3Ff3KLEX"
      },
      "source": [
        "model=Sequential()                                                     #initializing Sequential Layer\n",
        "model.add(Embedding(voc_size,dim,input_length=sent_length))             #vocabulary size, dimension, sentence length\n",
        "model.compile('adam','mse')                                            #compiling using 'adam' optimizer and performance metrics is Mean Square Error"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NHASWm4XKoBA",
        "outputId": "1b84be08-0a02-4044-f5b3-e4a79beb5bd6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_3 (Embedding)      (None, 8, 10)             100000    \n",
            "=================================================================\n",
            "Total params: 100,000\n",
            "Trainable params: 100,000\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6rYY_eC9Llen",
        "outputId": "27f2f2c0-283d-49d2-d101-ce8b7f251d8a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "print(embedded_docs[5] , embedded_docs[5][5])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[   0    0    0 5409 8817  990 6569 1343] 990\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NGTPbaWIK4_M"
      },
      "source": [
        "Lets see how we converted words into vectors"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-c87IL3rKtRZ",
        "outputId": "16528562-1c94-4540-c90d-20d0d5a255bc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "print(model.predict(embedded_docs[5]))                        #Representing  ---[0    0    0 5409 8817  990 6569 1343]--- as vectors with features(dimension = 10)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Model was constructed with shape (None, 8) for input Tensor(\"embedding_3_input:0\", shape=(None, 8), dtype=float32), but it was called on an input with incompatible shape (None, 1).\n",
            "WARNING:tensorflow:5 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f3437a80950> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "[[[-0.02767271  0.03654594  0.04781513 -0.02667452  0.02255342\n",
            "    0.00054307 -0.03754883 -0.01010317 -0.00422139 -0.02576688]]\n",
            "\n",
            " [[-0.02767271  0.03654594  0.04781513 -0.02667452  0.02255342\n",
            "    0.00054307 -0.03754883 -0.01010317 -0.00422139 -0.02576688]]\n",
            "\n",
            " [[-0.02767271  0.03654594  0.04781513 -0.02667452  0.02255342\n",
            "    0.00054307 -0.03754883 -0.01010317 -0.00422139 -0.02576688]]\n",
            "\n",
            " [[-0.01499424  0.0483135  -0.00327692  0.01478418  0.01499564\n",
            "   -0.02055746  0.01056106 -0.03667369  0.04790041  0.03533003]]\n",
            "\n",
            " [[ 0.03208775  0.01613034  0.00478371 -0.00219892  0.01611746\n",
            "    0.00046384  0.03118363  0.03733644  0.01539323  0.02085376]]\n",
            "\n",
            " [[ 0.01264114  0.01524791 -0.04914062  0.04310412  0.03832993\n",
            "   -0.03637781  0.0491089  -0.03810269  0.01335784  0.01907948]]\n",
            "\n",
            " [[ 0.00735407 -0.04406775 -0.04610842 -0.04319939  0.00202365\n",
            "   -0.03933302 -0.03061906  0.03929127  0.03564714  0.03536775]]\n",
            "\n",
            " [[-0.04039457  0.01517984  0.04057181  0.01157935  0.00515429\n",
            "   -0.01689434  0.03534528  0.04796915 -0.03710026  0.01906269]]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8YSUViK6K9ce"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}